{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подключение базовых библиотек для обработки изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from imutils import paths\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для работы с изображениями, найдем их гистограммы — характеристики распределения интенсивности изображения. Для этого можно воспользоваться следующим методом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_histogram(image, bins=(8, 8, 8)):\n",
    "    hist = cv2.calcHist([image], [0, 1, 2], None, bins, [0, 256, 0, 256, 0, 256])\n",
    "    cv2.normalize(hist, hist)\n",
    "    return hist.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считаем изображения из корневой папки train и вычислим гистограмму каждого изображения. Кроме того, отделим метку каждого изображения. Обработка большого числа изображений в облачных сервисах занимает длительное время (1-5 минут)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images('train')))\n",
    "trainData = []\n",
    "labels = []\n",
    "\n",
    "for (i, imagePath) in enumerate(imagePaths):\n",
    "    image = cv2.imread(imagePath, 1)\n",
    "    label = imagePath.split(os.path.sep)[-1].split(\".\")[0]\n",
    "    hist = extract_histogram(image)\n",
    "    trainData.append(hist)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем метки в удобный формат 0 и 1. Cat заменяем на 1, Dog на 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = [1 if x == 'cat' else 0 for x in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем первый базовый классификатор - бэггинг деревьев принятия решений (меняем значения возле комментариев на свои)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n                                                        max_leaf_nodes=20,\n                                                        min_samples_leaf=10,\n                                                        random_state=336),\n                  n_estimators=21, random_state=336)"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(criterion='entropy', #критерий разделения\n",
    "                              min_samples_leaf=10, #минимальное число объектов в листе\n",
    "                              max_leaf_nodes=20, #максимальное число листьев\n",
    "                              random_state=336) #random_state\n",
    "bagging = BaggingClassifier(tree, #базовый алгоритм\n",
    "                            n_estimators=21, #количество деревьев\n",
    "                            random_state=336) #random_state\n",
    "bagging.fit(trainData, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучим модель почти-разделяющий гиперплосоксти (меняем значения возле комментариев на свои)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "LinearSVC(C=1.51, random_state=336)"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "svm = LinearSVC(random_state = 336, C = 1.51) #random_state и C\n",
    "svm.fit(trainData, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И наконец обучаем третий базовый алгоритм — случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "RandomForestClassifier(criterion='entropy', max_leaf_nodes=20,\n                       min_samples_leaf=10, n_estimators=21, random_state=336)"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=21, #количество деревьев\n",
    "                             criterion='entropy', #критерий разделения\n",
    "                              min_samples_leaf=10, #минимальное число объектов в листе\n",
    "                              max_leaf_nodes=20, #максимальное число листьев\n",
    "                              random_state=336)\n",
    "forest.fit(trainData, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем в качестве решающего метаалгоритма логистическую регрессию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(solver='lbfgs', random_state=336) #solver и random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем метаалгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "StackingClassifier(cv=2,\n                   estimators=[('SVM', LinearSVC(C=1.51, random_state=336)),\n                               ('Bagging DT',\n                                BaggingClassifier(base_estimator=DecisionTreeClassifier(criterion='entropy',\n                                                                                        max_leaf_nodes=20,\n                                                                                        min_samples_leaf=10,\n                                                                                        random_state=336),\n                                                  n_estimators=21,\n                                                  random_state=336)),\n                               ('DecisionForest',\n                                RandomForestClassifier(criterion='entropy',\n                                                       max_leaf_nodes=20,\n                                                       min_samples_leaf=10,\n                                                       n_estimators=21,\n                                                       random_state=336))],\n                   final_estimator=LogisticRegression(random_state=336))"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "base_estimators = [('SVM', svm), ('Bagging DT', bagging), ('DecisionForest', forest)]\n",
    "sclf = StackingClassifier(estimators=base_estimators, final_estimator=lr, cv=2)\n",
    "sclf.fit(trainData, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценка метамодели. Доля правильной классификации (Accuracy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.852"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "sclf.score(trainData, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполняем предсказания для своих изображений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[0.55926714 0.44073286]]\n[[0.77809232 0.22190768]]\n[[0.53363117 0.46636883]]\n[[0.49613521 0.50386479]]\n"
    }
   ],
   "source": [
    "images = [cv2.imread('test/dog.1038.jpg'), cv2.imread('test/cat.1012.jpg'), cv2.imread('test/cat.1022.jpg'), cv2.imread('test/dog.1021.jpg')] #заменяем названия файлов\n",
    "#в выводе: первое число - вероятность отнесения изображения к собаке (0), а второе к кошке (1)\n",
    "for picture in images:\n",
    "    histt = extract_histogram(picture)\n",
    "    histt2 = histt.reshape(1, -1)\n",
    "    prediction = sclf.predict(histt2)\n",
    "    print(sclf.predict_proba(histt2), end=\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python38164bitfdd17f32668546a5ae7574a2749c4b27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}