{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Not_Programming_students.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pQu5IYHX8jId","colab_type":"text"},"source":["Настройка гиперпараметров модели"]},{"cell_type":"code","metadata":{"id":"Qf5Ji2nIHixN","colab_type":"code","colab":{}},"source":["epsilon = 0.1 # Параметр эпсилон при использовании эпсилон жадной стратегии\n","gamma = 0.9 # Коэффциент дисконтирования гамма\n","random_seed = 10 #Random seed\n","time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nwERyO-d_orM","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Вывод карты\n","lr_rate = 0.9 # Параметр альфа, отвечающиий за скорость обучения\n","\n","import gym\n","import numpy as np\n","import time\n","\n","\n","def generate_random_map(size, p, sd):\n","    \"\"\"Generates a random valid map (one that has a path from start to goal)\n","    :param size: size of each side of the grid\n","    :param p: probability that a tile is frozen\n","    \"\"\"\n","    valid = False\n","    np.random.seed(sd)\n","\n","    # DFS to check that it's a valid path.\n","    def is_valid(res):\n","        frontier, discovered = [], set()\n","        frontier.append((0,0))\n","        while frontier:\n","            r, c = frontier.pop()\n","            if not (r,c) in discovered:\n","                discovered.add((r,c))\n","                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n","                for x, y in directions:\n","                    r_new = r + x\n","                    c_new = c + y\n","                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n","                        continue\n","                    if res[r_new][c_new] == 'G':\n","                        return True\n","                    if (res[r_new][c_new] not in '#H'):\n","                        frontier.append((r_new, c_new))\n","        return False\n","\n","    while not valid:\n","        p = min(1, p)\n","        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n","        res[0][0] = 'S'\n","        res[-1][-1] = 'G'\n","        valid = is_valid(res)\n","    return [\"\".join(x) for x in res]\n","\n","\n","random_map = generate_random_map(size=6, p=0.8, sd = random_seed)\n","maze = random_map\n","env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #is slippery removes possibility to get in incorrect state after an action\n","print(\"Ваша карта\")\n","env.render()\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVSryhgomXjz","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Вывод количества побед и номера игры, когда впервые было одержано 5 побед подряд\n","def choose_action(state):\n","    action=0\n","    if np.random.uniform(0, 1) < epsilon:\n","        action = np.random.randint(0,env.action_space.n) #***\n","        #action = env.action_space.sample()\n","    else:\n","        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n","    return action\n","\n","def learn(state, state2, reward, action, done):\n","    #Q-learning\n","    if done:\n","      Q[state, action] = Q[state, action] + lr_rate * (reward - Q[state, action])\n","    else:\n","      Q[state, action] = Q[state, action] + lr_rate * (reward + gamma * np.max(Q[state2, :]) - Q[state, action])\n","\n","\n","from tqdm import tqdm\n","# Inititalization\n","wins_arr = [] #delete\n","np.random.seed(random_seed)\n","total_episodes = 10000\n","max_steps = 100\n","Q = np.zeros((env.observation_space.n, env.action_space.n))\n","min_episode = 0 #delete\n","#Main cycle\n","for episode in tqdm(range(total_episodes)):\n","    state = env.reset()\n","    t = 0\n","    while t < max_steps:\n","      #delete\n","        if episode > 5 and wins_arr[episode-5] == 1 and wins_arr[episode-4] == 1 and wins_arr[episode-3] == 1 and wins_arr[episode-2] == 1 and wins_arr[episode-1] == 1 and min_episode ==0:\n","          min_episode = episode\n","        \n","        t += 1\n","\n","        action = choose_action(state)\n","\n","        state2, reward, done, info = env.step(action)\n","\n","        if t == max_steps:\n","          done = True  \n","\n","        learn(state, state2, reward, action, done)\n","\n","        state = state2\n","\n","        if done and reward == 1:\n","          wins_arr.append(1) #record if won\n","          break\n","        if done:\n","          wins_arr.append(0) #record if lost\n","          break\n","\n","#print(\"Таблица ценностей действий\")\n","#print(np.round(Q,2))\n","#Number of wins\n","print('')\n","print(\"Количество побед в серии из 10 000 игр: \", np.sum(wins_arr))\n","#Number of the episode\n","print(\"Пять побед подряд впервые было одержано в игре \",min_episode)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hgojmJYxYUoM","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Отдельная игра после обучения\n","#Just 1 game to check if Q-table fits to win\n","from IPython.display import clear_output\n","import time\n","\n","def choose_action_one_game(state):\n","    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n","    return action\n","states=[]\n","t = 0\n","state = env.reset()\n","\n","while(t<1000):\n","  env.render()\n","  time.sleep(time_delay)\n","  clear_output(wait=True)\n","  action = choose_action_one_game(state)  \n","  state2, reward, done, info = env.step(action)  \n","  #print(reward)\n","  states.append(state)\n","  state = state2\n","  t += 1\n","  if done and reward == 1:\n","    wn=1\n","  if done:\n","    break\n","if wn == 1:\n","  print(\"!!!Победа!!!\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"cWOcJmAMNZPS","colab_type":"code","cellView":"form","colab":{}},"source":["#@title Построение карты маршрута\n","import matplotlib.pyplot as plt\n","\n","def make_maze_pic(maze):\n","  maze_pic=[]\n","  for i in range(len(maze)):\n","    row = []\n","    for j in range(len(maze[i])):\n","      if maze[i][j] == 'S':\n","        row.append(0)\n","      if maze[i][j] == 'F':\n","        row.append(0)\n","      if maze[i][j] == 'H':\n","        row.append(1)\n","      if maze[i][j] == 'G':\n","        row.append(0)\n","    maze_pic.append(row)\n","  maze_pic = np.array(maze_pic)\n","  return maze_pic\n","  \n","\n","#Make maze fit to plot\n","maze_pic = make_maze_pic(maze)\n","nrows, ncols = maze_pic.shape\n","\n","#Arrays of picture elements\n","rw = np.remainder(states,nrows)\n","cl = np.floor_divide(states,nrows)\n","rw = np.append(rw, [nrows-1])\n","cl = np.append(cl,[ncols-1])\n","\n","#Picture plotting\n","fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n","ax1.clear()\n","ax1.set_xticks(np.arange(0.5, nrows, step=1))\n","ax1.set_xticklabels([])\n","ax1.set_yticks(np.arange(0.5, ncols, step=1))\n","ax1.set_yticklabels([])\n","ax1.grid(True)\n","ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n","ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n","ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n","ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n","ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n","ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n","ax1.imshow(maze_pic, cmap=\"binary\")\n","\n"],"execution_count":0,"outputs":[]}]}